{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing all functions to get it working here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 \n",
    "import os\n",
    "import copy\n",
    "from sklearn.feature_extraction.image import PatchExtractor\n",
    "from skimage import data, transform\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Implementation (Other implelemtation below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_uglies():\n",
    "    match = False\n",
    "    for file_type in ['Negative']:\n",
    "        for img in os.listdir(file_type):\n",
    "            for ugly in os.listdir('Noimage'):\n",
    "                try:\n",
    "                    current_image_path = str(file_type)+'/'+str(img)\n",
    "                    ugly = cv2.imread('Noimage/'+str(ugly))\n",
    "                    question = cv2.imread(current_image_path)\n",
    "                    if ugly.shape == question.shape and not(np.bitwise_xor(ugly,question).any()):\n",
    "                        print('That is one ugly pic! Deleting!')\n",
    "                        print(current_image_path)\n",
    "                        os.remove(current_image_path)\n",
    "                except Exception as e:\n",
    "                    print(str(e))\n",
    "\n",
    "\n",
    "def create_pos_n_neg():\n",
    "    for file_type in ['Negative']:\n",
    "        for img in os.listdir(file_type):\n",
    "        \n",
    "            if file_type == 'pos':\n",
    "                line = file_type+'/'+img+' 1 0 0 50 50\\n'\n",
    "                with open('info.dat','a') as f:\n",
    "                    f.write(line)\n",
    "            elif file_type == 'Negative':\n",
    "                line = file_type+'/'+img+'\\n'\n",
    "                with open('bg.txt','a') as f:\n",
    "                    f.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Implementation (more promising, better understandable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positive Samples\n",
    "\n",
    "* prepare positive smples (download them!)\n",
    "* make annotations to positive samples \"opencv_annotations\" for EXTRACTION of object from samples\n",
    "* Reresize all logos to same size (smaller is better, as many logos as possible)\n",
    "* Get 2nd annotations file for resized logos for creation of .vec file using \"create_infodata_pos\"\n",
    "* create .vec file using \"opencv_createsamples\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ExtractObject(datafile, # annotation file\n",
    "                  pathtowrite):\n",
    "    #open datafile\n",
    "    f = open(datafile)\n",
    "    content = f.read()\n",
    "    i = 1\n",
    "    for l in content.split('\\n'):\n",
    "        words = l.split()\n",
    "        if(len(words) >= 6): # coz sometimes the images have no region. \n",
    "            img_path = ' '.join(words[:-5]) # path the positive sample file\n",
    "            img_path = img_path.replace('\\\\','/') # replace back-slash if you are window user\n",
    "            img = cv2.imread(img_path,0) # read the read the sample using OpenCV\n",
    "            logo = [int(w) for w in words[-4:]] #extract the logo\n",
    "            x,y,w,h = logo\n",
    "            if img is not None:\n",
    "                logograb = img[y:y+h, x:x+w]\n",
    "                # keep the size small to keep the training time short\n",
    "                img = cv2.resize(logograb, (60,60), interpolation = cv2.INTER_AREA)\n",
    "                cv2.imwrite(pathtowrite + str(i) + '.jpg', img)\n",
    "                i = i + 1\n",
    "            \n",
    "def create_infodata_pos(imgfolder):\n",
    "    for img in os.listdir(imgfolder):\n",
    "        line = imgfolder + img + \" 1 0 0 60 60\\n\"\n",
    "        with open(bg_name_positives,'a') as f:\n",
    "            f.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use opencv_annotations()\n",
    "# get annotations for extractions\n",
    "# Extract object\n",
    "path_training = \"./train/\"\n",
    "filename_extraction = \"annotations_for_extraction.txt\"\n",
    "\n",
    "bg_name_positives=\"bg_pos_test.txt\"\n",
    "bg_name_negatives=\"bg_neg_test.txt\"\n",
    "\n",
    "ExtractObject(filename_extraction,path_training)\n",
    "\n",
    "#Annotation file of Positive Samples (after cut out)\n",
    "# annotate again but with below function and not with \"opencv_annotations\"\n",
    "\n",
    "create_infodata_pos(path_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Negative Samples\n",
    "\n",
    "- Download negative samples\n",
    "- create X*Y sized patches from negative samples using \"extract_patches\"\n",
    "- Create bg.txt file to list all negative files using \"create_bg_neg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_patches(img, N, scale=1.0, patch_size=(60,60)):\n",
    "    extracted_patch_size = tuple((scale * np.array(patch_size)).astype(int))\n",
    "    extractor = PatchExtractor(patch_size=extracted_patch_size,\n",
    "                               max_patches=N, random_state=0)\n",
    "    patches = extractor.transform(img[np.newaxis])\n",
    "    if scale != 1:\n",
    "        patches = np.array([transform.resize(patch, patch_size)\n",
    "                            for patch in patches])\n",
    "    return patches\n",
    "\n",
    "\n",
    "def create_bg_neg(imgfolder,bg_name):\n",
    "    for img in os.listdir(imgfolder):\n",
    "        line = imgfolder + \"/\" + img + \"\\n\"\n",
    "        with open(bg_name,'a') as f:\n",
    "            f.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "source_neg = \"Negative\"\n",
    "patches_root= 'patches'\n",
    "subfolder = \"streets\"\n",
    "\n",
    "for filename in os.listdir(source_neg + '/' )[200:400]:# iterate thru each image in a celeb folder\n",
    "    filename = source_neg + '/'  + filename # build the path to the image file\n",
    "    if(filename.endswith('.jpg')):\n",
    "        img = cv2.imread(filename)\n",
    "        if(img is not None):\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            images.append(img)\n",
    "\n",
    "negative_patches = np.vstack([extract_patches(im, 75, scale)\n",
    "                             for im in images for scale in [1.0]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image in range(0,len(negative_patches)):\n",
    "    cv2.imwrite(patches_root + \"/\" + subfolder + \"/\"+str(image)+\".jpg\", negative_patches[image,:,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_bg_neg(patches_root + \"/\" +subfolder,bg_name_negatives)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Cascade\n",
    "\n",
    "* using opencv_traincascade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect(faceCascade, gray_,  scaleFactor_ = 1.05, minNeighbors = 3):\n",
    "    faces = faceCascade.detectMultiScale(gray_,\n",
    "                    scaleFactor= scaleFactor_,\n",
    "                    minNeighbors=5,\n",
    "                    minSize= (30,30), #(60, 20),\n",
    "                    flags = cv2.CASCADE_SCALE_IMAGE\n",
    "                )\n",
    "    return faces\n",
    "\n",
    "source_positive = \"/home/jannik/Git-master/justice_detection/pos/\"\n",
    "cascade_path = \"./cascade/cascade.xml\"\n",
    "\n",
    "def DetectAndShow(imgfolder,cascade_path):\n",
    "    cascade_classifier = cv2.CascadeClassifier(cascade_path)\n",
    "    for i in os.listdir(imgfolder):\n",
    "        filepath = imgfolder + i\n",
    "        img = cv2.imread(filepath)\n",
    "\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        logos = detect(cascade_classifier, gray, 1.25, 6)\n",
    "        for (x, y, w, h) in logos:\n",
    "            cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        cv2.imshow('positive samples',img)\n",
    "        k = 0xFF & cv2.waitKey(0)\n",
    "        if k == 27:         # q to exit\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DetectAndShow(source_positive,cascade_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
